# prepare（必须）:
#   1、程序运行前，首先需要初始化程序数据表
#   2、配置 reverse 自定义转换规则
#   - 优先级：表字段类型 > 库字段类型 两者都没配置默认采用内置转换规则
# reverse:
#   1、prepare 前提必须阶段
#   2、根据内置表结构转换规则或者手工配置表结构转换规则进行 schema 迁移
# gather:
#   1、用于收集评估 oracle -> mysql/tidb 迁移成本信息，只适用于 schema 级别
# check:
#   1、表结构检查(独立于表结构转换，可单独运行，校验规则使用内置规则)
# all:（全量 + 增量模式）
#   1、全量数据迁移
#   2、增量数据迁移
# full: (全量模式)
#   1、全量数据迁移 -> REPLACE INTO
# csv：（全量模式）
#   1、全量数据导出 -> CSV
[app]
# 事务 batch 数
# 用于数据写入 batch 提交事务数
insert-batch-size = 500
# 是否开启更新元数据库表慢日志，单位毫秒
slowlog-threshold = 300
# 任务并发 -- 只用于 reverse/check 模式阶段
threads = 8
# pprof 端口
pprof-port = ":9696"

[csv]
# CSV 文件是否包含表头
header = true
# 字段分隔符，支持一个或多个字符，默认值为 ','
# 行分隔符 terminator，统一用 "\r\n"（回车+换行）,无需手工修改
separator = ','
# 字符串引用定界符，支持一个或多个字符，设置为空表示字符串未加引号
delimiter = '"'
# 使用反斜杠 (\) 来转义导出文件中的特殊字符
escape-backslash = true
# 目标数据库字符集 utf8/gbk，设置为空表示以上游数据库为准
charset = "utf8"
# 多少行数据切分一个 csv 文件
rows = 20000
# 数据文件输出目录, 所有表数据输出文件目录，需要磁盘空间充足
output-dir = "/data"
# 任务 chunk 数，固定动作，一旦确认，不能更改，除非设置 enable-checkpoint = false，重新导出导入
# 1、代表每张表每并发处理多少行数
# 2、建议参数值是 rows 整数倍，会根据 rows 大小切分
chunk-size = 2000000
# 表导出导入并发数，同时处理多少张上游表，可动态变更
worker-threads = 8
# 单表并发数，表内并发，表示同时多少并发 SQL 读取上游表数据，可动态变更
table-threads = 64
# csv 并发写线程数，表示同时多少个 csv 文件同时写，可动态变更
apply-threads = 64
# 关于全量断点恢复
#   - 若想断点恢复，设置 enable-checkpoint = true,首次一旦运行则 chunk-size 数不能调整，
#   - 若不想断点恢复或者重新调整 chunk-size 数，设置 enable-checkpoint = false,重新运行全量任务
#   - 有可能无法断点续传，则需要设置 enable-checkpoint = false 重新导入导出
enable-checkpoint = true

[full]
# 按照表级别操作导出导入
# 任务 chunk 数，固定动作，一旦确认，不能更改，除非设置 enable-checkpoint = false，重新导出导入
# 1、代表每张表每并发处理多少行数
# 2、建议参数值是 insert-batch-size 整数倍，会根据 insert-batch-size 大小切分
chunk-size = 200000
# 表导出导入并发数，同时处理多少张上游表，可动态变更
worker-threads = 8
# 单表 SQL 执行并发数，表内并发，表示同时多少并发 SQL 读取上游表数据，可动态变更
table-threads = 64
# 下游并发写线程数，可动态变更
apply-threads = 64
# 关于全量断点恢复
#   - 若想断点恢复，设置 enable-checkpoint = true,首次一旦运行则 chunk-size 数不能调整，
#   - 若不想断点恢复或者重新调整 chunk-size 数，设置 enable-checkpoint = false,重新运行全量任务
#   - 有可能无法断点续传，则需要设置 enable-checkpoint = false 重新导入导出
enable-checkpoint = true

[all]
# logminer 挖掘最长耗时，单位: 秒
logminer-query-timeout   = 300
# 并发筛选 oracle 日志数
filter-threads = 16
# 并发表应用数，同时处理多少张表
apply-threads = 3
# apply-threads 每个表并发处理最大工作对列
worker-queue = 3
# apply-threads 每个表并发处理最大任务分发数
worker-threads = 3

[source]
# 源端 oracle 连接串
# 若需要增量数据同步，则需要 logminer 权限
username = "marvin"
password = "marvin"
# 配置 oracle 连接字符串，样例：主机地址:数据库端口/服务名?参数
connect-string = "172.16.4.182:1521/orcl?connect_timeout=2"
# 配置 oracle 连接会话 session 变量,
session-params = ["alter session set nls_date_format = 'yyyy-mm-dd hh24:mi:ss'"]
# 配置 oracle 连接时区
timezone = "Local"
# 配置 oracle 迁移 schema（gather 阶段可设置可不设置，不设置则表示 gather 库内所有 schema，其他阶段必须设置）
schema-name = "marvin"
# 源端迁移任务表（只用于 prepare/reverse/check/all/full 阶段，gather 阶段不适用，gather 只适用于 schema 级别）
# include-table 和 exclude-table 不能同时配置，两者只能配置一个,如果两个都没配置则 Schema 内表全迁移
include-table = []
exclude-table = []

# 只用于 prepare/reverse/check/all/full 阶段，gather 阶段不适用
[target]
# 目标端 mysql 连接串
username = "marvin"
password = "marvin"
host = "172.16.4.207"
port = 4000
# mysql 链接参数
connect-params = "charset=utf8mb4&parseTime=True&loc=Local&multiStatements=true"
# 目标端元数据库
# CREATE DATABASE IF NOT EXIST db_meta
meta-schema = "db_meta"
# 目标端导入 schema
schema-name = "steven"


[log]
# 日志 level
log-level = "info"
# 日志文件路径
log-file = "./conf/transferdb.log"
# 每个日志文件保存的最大尺寸 单位：M
max-size = 128
# 文件最多保存多少天
max-days = 7
# 日志文件最多保存多少个备份
max-backups = 30